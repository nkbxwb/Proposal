\chapter{Discussion}
We have discussed a number or tools and methods to analyze survival data with missingness.  There are lots of decisions to be made along the way, and I am in no way advocating that my exact choices are the right ones, I am only claiming that the decisions made were proper for the type of data that we had.
There will certainly be many disagreements about the multiple imputation portion. And since the multiple imputation serves as the root of the analysis, the concerns should be addressed. The first concern comes from people who don’t understand or believe in imputation of missing values. Multiple imputation is a tool to help us find plausible values for missing data. We will make no claim that the imputed values are right, but when used correctly, the results will be unbiased. We aren’t using multiple imputation to create data where there is none, we are using it to “fill gaps”. In fact, there exist situations where not imputing could lead to biased results due to sampling bias (for example, if teenage males who are obese don’t want to self-report their weight, then classic complete or available case analysis will yield biased results because we have knowingly left out part of the population). We need to impute to make sure we have included all of the information and not to bias our estimate.
The next and more substantial critique will come from statisticians who may not believe that the distribution that the imputations are being drawn from are valid. Multiple imputation is inherently a parametric procedure. No matter what method we use to impute, we have to make a parametric assumption, be it the joint model for JM or the full conditionals for FCS.  For our case, using the normal model is certainly wrong, so we are left only with using FCS. And FCS alone has weak theoretical justification. But as we have discussed before, many studies have shown that FCS is robust to non compatibility. An interesting extension to this project would be to use a non parametric approach to multiple imputation, such as the one suggested by Long et all in \cite{Long2012}. But at the time of publication, there is not much literature or software on this subject, so I felt that it was not appropriate to use its results.  Multiple imputation is becoming the standard for missing data techniques, especially in the medical field. There are lots of pros to it, but there are certainly some conns. Much research has already gone in to it, but much more needs to be done.
Next we can critique the survival section. We decided to use standard Kaplan-Meier and cox analyses because they are very standard in practice, and answer the questions well. However, some lesser known methods could have been used. A popular theoretical model is called the accelerated failure time model, which describes how covariates effect the hazard, assuming that it acts in a multiplicative fashion. This is useful for clinicians, but not really good for patients, because the conclusions drawn from it are “drug x will make you live 50% longer than y”, and this type of wording conveys more optimism about the model than there really is. 
Next, since there is no well established method to validate the model, we had to be creative and define our own methods to check them. The methods are reasonable and both the stacked and individual methods are very similar. More research should be done though to verify if this will always be the case, specifically in the presence of pathological data. 
There are two concepts that are interesting, but our data did not allow for it. The first is variable selection. The clinicians knew what they wanted to test, so this was not needed, but variable selection in the context of MI is an interesting question, and van Buuren covers it in his book \cite{VanBuuren2012}. This would be very useful if our dataset had covariates that we were unsure of or wanted to examine. 
Another interesting addition would be using multistate data. In this setting, subjects can transfer from one group to another, ie have cancer, get in to remission, and then relapse.  We model the states as a stochastic process. This would be really interesting, and I would have liked to implement it because I think it would have been interesting from a multiple imputation perspective, but unfortunately our data was not conducive to that.
Lastly, we move on to the causal analysis part. While there are many other binary classifiers that could be used to make propensity scores, we chose to use logistic regression. This choice was based solely on tradition and ease of understanding from non statisticians. As well, there has been some new research recently saying that propensity score matching is not as powerful as it was once thought  (? King?). Lastly, our choice of how to combine propensity scores was solely based off of the Mitra paper, and no more studies have been done to show that this is in fact the optimal way to do it. 
