\chapter{Application}
\section{Data Explanation}
\label{sec:data}
Now that we have the theory in place, we can apply it to some real data. The dataset that I chose to analyze is a dataset from MD Anderson cancer center, with permission from Dr. Bugano (get the permission!!). This dataset has historical records of X MD Anderson patients who have had breast cancer that has metastasized to the brain, and it records many covariate, treatments, as well as survival endpoints. This data is exemplary for this task because it is large, survival amenable, has missingness that is easy to impute on, and has treatment variables.
Our first step is to define what we would like to find. There are many interesting questions we could ask from this data because of the amount of data available, but the question I will focus on here is the effect on survival and treatment of two HER2 therapeutic drugs-Lapatinib and Trastuzumab. For a much more detailed analysis and other clinically relevant questions, see !!Hess, Bugano, Berliner!!. So, we will want to check out survival curves and cox regression, as well as analyze the treatment effect.
We first need to impute the missing data. This is a little challenging just because of the sheer number of covariates that we have. But we need these covariates. With more covariates, the more sure we can be in the assumption of MAR missingness. As well, it is better to have too many covariates than not enough. The model is set up, and the appropriate methods are selected for each datatype. The mice algorithm from the R package mice is run. For 50 datasets, 40 iterations, the algorithm runs in about X hours. While this seems like a long time, this only needs to be done once.
Convergence is assessed, and diagnostic plots are viewed to ensure that the imputed data is similar enough to the real data. A few of the plots have been replicated here. To see all of the plots, go to the shiny app (do this if enough time).  Not all of the imputed data follows the distribution of the observed data exactly, but we obviously don’t expect this to happen.
Now that the datasets are imputed, we are ready to run our models on them.  As a sanity check, we may compare them to available case analysis. Since the imputed values we generate ought to be quite similar to what data we have, we should expect our estimates to be similar.
The first result that we will check is the Kaplan Meier curves for the imputed data. The available case analysis seems to show that lapatinib and trastuzumab are quite close to each other, with no treatment being much lower. The results from MI look quite similar. [put the stuff in]. The pooled KM estimate was found using Rubin’s rules, but under a cloglog transform as suggested by \cite{Marshall2009} to get towards normality.  We can also run a log-rank test on the MI data. This was implemented by \cite{Zhao2014} using another form of imputation called kmmi, but it has not ever been used on regular MI (kmmi works on missing censoring times). Log rank test is a normally distributed quantity asymptotically, so we can just pool it as normal and use the degrees of freedom from Rubin and Barnard to get our inference.  !! put the analysis here!!
!!!Do I want to do competing risks analysis?!!!
Now that we have estimate of survival, we may set up a model to observe how changes in some baseline covariates change the hazard. To do this, we need to run a Cox proportional hazards model. The original available case model is as follows.  We need to make sure that the proportional hazards assumption is met, so we may check the cox zph command to look at the schoenfeld residuals over time, and check the test stat. Overall, it looks to be proportional hazards over time, and the test statistic affirms this.  Then, we fit that same cox model on all of our imputed data sets, and pool our results via Rubin’s rules (no transformation needs to be done since the cox model coefficients assume asymptotical normality). We need to verify that we still have proportional hazards though. This is not an easy task, since we don’t actually have a model, rather, we have the average of multiple models. We are no longer estimating the parameters by maximizing the partial likelihood, rather we are estimating them based on the average of the coefficients from the MI datasets. There are two ways we can go about this. The first is to check the proportional hazards assumptions on the stacked dataset.  This will give us a good visualization about the shape of the proportional hazards over time, but when running the chi square test to check for the correlation between the coefficient and time, the sample will be artificially too big, and thus we cannot trust the results. The correct way to do this is to observe each plot and statistic generated from the m datasets to see if the assumptions hold. This may seem like an arduous task when the number of imputed datasets is large, but we can circumvent it by writing a shiny app to view them, or plot all of the loess curves on one plot. We can also get the average of the chi square test results if we need a little more information than looking at the plots. Overall though, our imputed plots are very similar to the plots produced by complete case analysis, to which we have deemed to be acceptable for the proportional hazards assumption. We may now look at the cox regression coefficients and exponentiate them in order to obtain the hazard ratios. Looking at !! table whatever!! , we can see that some factors force a larger hazard ratio than others. We can take the reciprocal of it to look at the protective effects of each covariate.
Lastly, we will want to draw causal inference, and see what the average treatment effect of each drug is. This is necessary because the data was collected from a database, and we did not have a completely randomized experiment.  As well, this piece of information is what clinicians and laypeople really want—it answers the question of which drug is better. There are many interesting questions that we may ask with this dataset, but here we will only focus on lapatinib vs trastuzumab vs no treatment. The interested reader may read !!my paper!! Upon its publication. The idea for this part of the analysis is to use propensity scores to match subjects and then compare them. As we saw earlier the best way to match is using the X method. There are several R packages to do propensity score matching in R, including X Y Z . I chose to use the X package because of its ease of use. Do a lot more work on this part!!!!!
